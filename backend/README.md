# CV Analysis System - Backend

## ğŸš€ Project Overview
The **CV Analysis System** is a powerful AI-driven resume processing backend built with **Django, NLP, and Groq's LLaMA-3.3-70B model**. This system processes multiple resume documents, extracts structured information using **OCR and NLP**, and allows advanced **LLM-powered querying** via a chatbot interface. It also includes an **advanced resume search engine** for filtering candidates based on skills, experience, education, and certifications.

### âœ¨ **Key Features**
âœ… **Resume Upload & Parsing**: Supports **PDF & DOCX** formats, extracts text via **OCR** and organizes details into structured data.
âœ… **Advanced Regex + NLP Extraction**: Extracts **Personal Information, Education, Work Experience, Skills, Projects, and Certifications**.
âœ… **Groq API Integration**: Uses **LLaMA-3.3-70B** for **intelligent resume querying**.
âœ… **Multi-Turn Conversational AI**: Tracks chat history for **context-aware resume queries**.
âœ… **Optimized API Performance**: Implements **rate limiting, caching, and batch query processing**.
âœ… **Advanced Resume Search**: Find candidates by **skills, experience, education, and certifications**.

---

## ğŸ“‚ **Project Structure**
```
backend/
â”‚â”€â”€ document_processing/   # Core resume parsing & query processing
â”‚   â”œâ”€â”€ models.py         # Database models (Resume, PersonalInfo, Education, etc.)
â”‚   â”œâ”€â”€ views.py          # API views (upload, query, search, etc.)
â”‚   â”œâ”€â”€ groq_api.py       # LLM Query Handler
â”‚   â”œâ”€â”€ utils.py          # NLP & regex parsing functions
â”‚â”€â”€ backend/
â”‚   â”œâ”€â”€ settings.py       # Django settings (DB, API Keys, Cache, etc.)
â”‚â”€â”€ requirements.txt      # Dependencies
â”‚â”€â”€ README.md             # Documentation
```

---

## ğŸ›  **Setup & Installation**

### **2ï¸âƒ£ Set Up a Virtual Environment**
```bash
python3 -m venv venv
source venv/bin/activate  # For Mac/Linux
venv\Scripts\activate    # For Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ Configure Environment Variables**
Create a `.env` file and add the following:
```env
GROQ_API_KEY=your_groq_api_key
```

### **5ï¸âƒ£ Apply Database Migrations**
```bash
python manage.py makemigrations document_processing
python manage.py migrate
```

### **6ï¸âƒ£ Run the Server**
```bash
python manage.py runserver
```

---

## ğŸ”¥ **How to Use the API**
### **1ï¸âƒ£ Upload a Resume**
**Endpoint:** `/api/document_processing/upload/`  
**Method:** `POST`  
**Payload:**
```json
{
    "file": "your_resume.pdf"
}
```
**Response:**
```json
{
    "message": "File uploaded successfully",
    "resume_id": 5
}
```

---

### **2ï¸âƒ£ Query a Resume (LLM-Powered)**
**Endpoint:** `/api/document_processing/query/`  
**Method:** `POST`  
**Payload (Single Query):**
```json
{
    "resume_id": 5,
    "query": "What programming languages does the candidate know?"
}
```
**Payload (Batch Queries):**
```json
{
    "resume_id": 5,
    "queries": [
        "What programming languages does the candidate know?",
        "What is the candidate's most recent job experience?"
    ]
}
```

---

### **3ï¸âƒ£ Search Candidates by Criteria**
**Endpoint:** `/api/document_processing/search/`  
**Method:** `POST`  
**Payload:**
```json
{
    "skills": ["Python", "Django"],
    "min_experience": 3,
    "education_level": "Master",
    "certifications": ["AWS Certified"]
}
```
